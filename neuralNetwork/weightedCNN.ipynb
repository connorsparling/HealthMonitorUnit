{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x105a74790>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split # used for splitting training and testing data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# time steps per batch of data\n",
    "seq_length = 100\n",
    "\n",
    "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
    "\n",
    "data = pd.read_csv('../Datasets/SectionData.csv')\n",
    "\n",
    "x = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, kernel_size, hidden_size, drop_prob):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(1, 1, kernel_size),\n",
    "            #nn.Conv1d(1, 1, kernel_size),\n",
    "            #nn.Relu()\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Linear(input_size - kernel_size + 1, hidden_size[0]),\n",
    "            nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "            nn.Linear(hidden_size[1], hidden_size[2]),\n",
    "            nn.LogSoftmax(dim=1), # NLLLoss\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAT_TYPES_INDEX = {\n",
    "    'N': 0,\n",
    "    'L': 1,\n",
    "    'R': 2,\n",
    "    'A': 3,\n",
    "    'V': 4,\n",
    "    'F': 5,\n",
    "}\n",
    "\n",
    "def formatDataX(data):\n",
    "    temp = torch.tensor(data).float()\n",
    "    return temp.view(temp.size(0), 1, temp.size(1))\n",
    "\n",
    "def formatDataY(data):\n",
    "    return torch.tensor(data).float()\n",
    "\n",
    "def preprocess(df):\n",
    "\n",
    "    # drop ecgNum row\n",
    "    df = df.drop([\"ecgNum\"], axis=1)\n",
    "    # Classify the dependent and independent variables\n",
    "    X = df.iloc[:, :-1].values\n",
    "    labels = df.iloc[:, -1].values\n",
    "    Y = np.array([np.insert(np.zeros(5), BEAT_TYPES_INDEX[label], 1) for label in labels])\n",
    "    \n",
    "    # split the data into train, validate, test\n",
    "    X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.2, random_state=0)\n",
    "    \n",
    "    class_weights = compute_class_weight('balanced', ['N','L','R','A','V','F'], labels)\n",
    "    \n",
    "    print(class_weights)\n",
    "    \n",
    "    class_weights = class_weights * [10.0, 1, 1, 1, 1, 0.5]\n",
    "    \n",
    "    print(class_weights)\n",
    "    \n",
    "    return formatDataX(X_train), formatDataX(X_val), formatDataX(X_test), formatDataY(Y_train), formatDataY(Y_val), formatDataY(Y_test), formatDataY(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, X_test, Y_train, Y_val, Y_test, weights = preprocess(data)\n",
    "#print(X_train.size())\n",
    "#print(X_val.size())\n",
    "#print(X_test.size())\n",
    "#print(Y_train.size())\n",
    "#print(Y_val.size())\n",
    "#print(Y_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (model): Sequential(\n",
      "    (0): Conv1d(1, 1, kernel_size=(20,), stride=(1,))\n",
      "    (1): Flatten()\n",
      "    (2): Dropout(p=0.01, inplace=False)\n",
      "    (3): Linear(in_features=181, out_features=64, bias=True)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): Linear(in_features=32, out_features=6, bias=True)\n",
      "    (6): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# size of the input at each time step\n",
    "# TODO: handle input sizes\n",
    "input_size = 200\n",
    "# kernel size\n",
    "kernel_size = 20\n",
    "# size of the hidden state and cell state at each time step\n",
    "hidden_size = [64, 32, 6]\n",
    "# dropout probability\n",
    "drop_prob = 0.01\n",
    "\n",
    "# instantiate the NN\n",
    "neuralNet = NeuralNetwork(input_size, kernel_size, hidden_size, drop_prob)\n",
    "print(neuralNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error and Adam Optimizer with a learning rate of 0.01\n",
    "# TODO: play with LR\n",
    "#criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "#optimizer = torch.optim.Adam(neuralNet.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22417539  2.07594911  2.31045977  6.58444706  2.35330617 20.88632585]\n",
      "[ 2.24175388  2.07594911  2.31045977  6.58444706  2.35330617 10.44316293]\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "print_every = 45\n",
    "\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test, weights = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, X, Y, print_conf=True):\n",
    "    resValues, resIndices = torch.max(net(X), 1)\n",
    "    length = len(resIndices.numpy())\n",
    "    testValues, testIndices = torch.max(Y, 1)\n",
    "    results = np.array([np.insert(np.zeros(5), index, 1) for index in resIndices])\n",
    "    \n",
    "    conf_matrix = confusion_matrix(resIndices.numpy(), testIndices.numpy())\n",
    "\n",
    "    correct = 0\n",
    "    for i in range(len(conf_matrix)):\n",
    "        correct += conf_matrix[i,i]\n",
    "        \n",
    "    print(\"Accuracy: {:.2%}\".format(correct/length))\n",
    "    if print_conf:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the NN\n",
    "def train(net, X, Y, num_epochs, weights):  \n",
    "    criterion = nn.NLLLoss(weights) \n",
    "    \n",
    "    #optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "    \n",
    "    for epoch in range (num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = net(X)\n",
    "        \n",
    "        # NLLLoss\n",
    "        actValues, actIndices = torch.max(Y, 1)\n",
    "        loss = criterion(out, actIndices)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 50 == 0:\n",
    "            test(net, X_test, Y_test, False)\n",
    "            print(\"Epoch {} of {} => Loss {:.4f}\".format(epoch+1, num_epochs, loss.item()))\n",
    "        else:\n",
    "            print(\"Epoch {} of {} => Loss {:.4f}\\r\".format(epoch+1, num_epochs, loss.item()), end=\"\")\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.85%=> Loss 1.1103\n",
      "\n",
      "\n",
      "Accuracy: 74.85%=> Loss 1.0850\n",
      "\n",
      "\n",
      "Epoch 136 of 500 => Loss 1.0053\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-40dc4cb3413e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_NN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuralNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-a52642522b66>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, X, Y, num_epochs, weights)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactIndices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/HealthMonitorNN/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/HealthMonitorNN/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_NN = train(neuralNet, X_train, Y_train, epochs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.60%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[46578  3503  2203   652  2704   299]\n",
      " [  474  1372    29    51   233     1]\n",
      " [  162    13  2286    39    94     2]\n",
      " [  208   119   142   840   205     5]\n",
      " [  209   130    12    52  1203     7]\n",
      " [   69    23     5     4   189   206]]\n",
      "Accuracy: 81.99%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14683  1119   655   189   767    97]\n",
      " [  163   416     3    18    55     0]\n",
      " [   60     6   725    10    29     0]\n",
      " [   64    40    55   249    88     0]\n",
      " [   55    47     6    19   350     0]\n",
      " [   20     3     2     4    46    58]]\n",
      "Accuracy: 82.01%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11696   859   495   157   667    69]\n",
      " [  113   352     6    28    62     1]\n",
      " [   42     2   584    12    27     0]\n",
      " [   52    22    37   202    56     1]\n",
      " [   49    40     1    15   299     1]\n",
      " [   25     3     4     3    44    55]]\n"
     ]
    }
   ],
   "source": [
    "test(trained_NN, X_train, Y_train)\n",
    "test(trained_NN, X_test, Y_test)\n",
    "test(trained_NN, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/connorsparling/opt/anaconda3/envs/HealthMonitorNN/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NeuralNetwork. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(trained_NN, \"../Models/TestingCNN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateNNData(data):\n",
    "    x = torch.tensor(data).float()\n",
    "    x = x.view(1, 1, x.size(1))\n",
    "    resValues, resIndices = torch.max(trained_NN(x), 1)\n",
    "    return resIndices[0]\n",
    "\n",
    "def giveMeABad():\n",
    "    testValues, testIndices = torch.max(Y_test, 1)\n",
    "    for i in range(len(testIndices)):\n",
    "        result = evaluateNNData(X_test[i])\n",
    "        if result != 0:\n",
    "            print(i)\n",
    "            for x in X_test[i][0].numpy():\n",
    "                print(str(x) + \",\", end=\"\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giveMeABad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
